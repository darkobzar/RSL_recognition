{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd2cd4-ba6d-4a48-866b-41b6ab62eda7",
   "metadata": {
    "id": "05cd2cd4-ba6d-4a48-866b-41b6ab62eda7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,garbage_collection_threshold:0.8\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cebdf5-5905-42be-85b5-6ee9866544c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./RSL.yaml\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b264e3-6c30-45e2-b6f2-feaacc5872af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from VideoMAE import MixedGestureDataset, VideoGestureDataset, collate_fn, plot_class_distribution, train, show_clip_from_dataset, evaluate_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b52d6a-4578-4f19-b11c-ab8310d73110",
   "metadata": {
    "id": "d2b52d6a-4578-4f19-b11c-ab8310d73110"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: torch.clamp(x * 1.3, 0, 1)),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "train_dataset = MixedGestureDataset(\n",
    "    video_frames_dir=config['vit']['train_vid'],\n",
    "    video_ann_path=config['vit']['train_vid_anno'],\n",
    "    image_dir=config['vit']['train_img'],\n",
    "    image_ann_path=config['vit']['train_img_anno'],\n",
    "    clip_len=8,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = VideoGestureDataset(\n",
    "    frames_dir=config['vit']['val_vid'],\n",
    "    ann_path=config['vit']['val_vid_anno'],\n",
    "    clip_len=8,\n",
    "    transform=transform,\n",
    "    label2id=train_dataset.label2id\n",
    ")\n",
    "\n",
    "test_dataset = VideoGestureDataset(\n",
    "    frames_dir=config['vit']['test_vid'],\n",
    "    ann_path=config['vit']['test_vid_anno'],\n",
    "    clip_len=8,\n",
    "    transform=transform,\n",
    "    label2id=train_dataset.label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf70eb4-4583-4c03-8a48-3567fbb30efa",
   "metadata": {
    "id": "7cf70eb4-4583-4c03-8a48-3567fbb30efa"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1bfa99-d0df-49ec-b793-10fe16476fe5",
   "metadata": {
    "id": "fc1bfa99-d0df-49ec-b793-10fe16476fe5"
   },
   "outputs": [],
   "source": [
    "from transformers import VideoMAEForVideoClassification\n",
    "import torch.nn as nn\n",
    "\n",
    "model = VideoMAEForVideoClassification.from_pretrained(\n",
    "    config['vit']['pr_model'],\n",
    "    num_labels=len(train_dataset.label2id),\n",
    "    ignore_mismatched_sizes=True,\n",
    "    num_frames=8,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    hidden_dropout_prob=0.2\n",
    ")\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(model.config.hidden_size, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, model.config.num_labels )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e57153a-ba30-469e-b100-9a0b74bfcd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls={\n",
    "    'l1': 'А',\n",
    "    'l2': 'Б',\n",
    "    'l3': 'В',\n",
    "    'l4': 'Г',\n",
    "    'l5': 'Д',\n",
    "    'l6': 'Е',\n",
    "    'l7': 'Ё',\n",
    "    'l8': 'Ж',\n",
    "    'l9': 'З',\n",
    "    'l10': 'И',\n",
    "    'l11': 'Й',\n",
    "    'l12': 'К',\n",
    "    'l13': 'Л',\n",
    "    'l14': 'М',\n",
    "    'l15': 'Н',\n",
    "    'l16': 'О',\n",
    "    'l17': 'П',\n",
    "    'l18': 'Р',\n",
    "    'l19': 'С',\n",
    "    'l20': 'Т',\n",
    "    'l21': 'У',\n",
    "    'l22': 'Ф',\n",
    "    'l23': 'х',\n",
    "    'l24': 'Ц',\n",
    "    'l25': 'Ч',\n",
    "    'l26': 'Ш',\n",
    "    'l27': 'Щ',\n",
    "    'l28': 'Ъ',\n",
    "    'l29': 'Ы',\n",
    "    'l30': 'Ь',\n",
    "    'l31': 'Э',\n",
    "    'l32': 'Ю',\n",
    "    'l33': 'Я'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f858837c-5e8d-4d5f-8078-f4ac233a0ed3",
   "metadata": {
    "id": "f858837c-5e8d-4d5f-8078-f4ac233a0ed3"
   },
   "outputs": [],
   "source": [
    "plot_class_distribution(val_dataset, lbls, 'валидационном')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81bb95-e3d1-4317-912b-114c5442801c",
   "metadata": {
    "id": "aa81bb95-e3d1-4317-912b-114c5442801c"
   },
   "outputs": [],
   "source": [
    "plot_class_distribution(train_dataset, lbls, \"обучающем\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46feb7-00ac-492f-84df-7f82a5b4ccc0",
   "metadata": {
    "id": "6b46feb7-00ac-492f-84df-7f82a5b4ccc0"
   },
   "outputs": [],
   "source": [
    "plot_class_distribution(test_dataset, lbls, \"тестовом\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce5acc6-f15e-45f1-99ae-0aa4aad5119d",
   "metadata": {
    "id": "fce5acc6-f15e-45f1-99ae-0aa4aad5119d"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22a50d-e044-436d-9e6f-fccff1a79727",
   "metadata": {
    "id": "fb22a50d-e044-436d-9e6f-fccff1a79727",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    epochs=10,\n",
    "    lr=1e-5,\n",
    "    log_dir=config['vit']['log_dir']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b14f638-24ef-47de-8000-1f40c04ee346",
   "metadata": {
    "id": "0b14f638-24ef-47de-8000-1f40c04ee346"
   },
   "outputs": [],
   "source": [
    "show_clip_from_dataset(train_dataset, idx=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc34598-5009-404b-b05b-c50dde4d56bb",
   "metadata": {
    "id": "fdc34598-5009-404b-b05b-c50dde4d56bb"
   },
   "outputs": [],
   "source": [
    "evaluate_test(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
